{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ed84ce",
   "metadata": {},
   "source": [
    "## _LLM Powered Chatbot_ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66f16436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86bb93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd6dc75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f5e7c57af80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f5e86ba87c0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Chatmodel\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='gemma2-9b-it',\n",
    "                 groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae07a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Aswin,\\n\\nIt's nice to meet you! \\n\\nIt's great to hear you're a Data Engineer at Infosys. That's a fascinating field. \\n\\nWhat kind of data engineering projects are you currently working on?  \\n\\nI'm always eager to learn more about how data is being used to solve real-world problems.\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "response = model.invoke([\n",
    "    HumanMessage(content='Hi I am Aswin ,I am a data Engineer with Infosys')\n",
    "])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3d407e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You told me your name is Aswin and that you are a Data Engineer at Infosys. ðŸ˜Š  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 113, 'total_tokens': 148, 'completion_time': 0.063636364, 'prompt_time': 0.005479238, 'queue_time': 0.24394570200000001, 'total_time': 0.069115602}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-db6b5958-5672-4b5f-a8ba-4d3cf761fe19-0', usage_metadata={'input_tokens': 113, 'output_tokens': 35, 'total_tokens': 148})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content='Hi I am Aswin ,I am a data Engineer with Infosys'),\n",
    "    AIMessage(content =\"Hi Aswin,\\n\\nIt's nice to meet you! It's great to hear you're a Data Engineer at Infosys. That's a fascinating field. \\n\\nWhat kind of data engineering projects are you currently working on?  \\n\\nI'm always eager to learn more about how data is being used to solve real-world problems.\\n\"),\n",
    "    HumanMessage(content=\"Whats my name and occupation?\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444946a",
   "metadata": {},
   "source": [
    "#### _Message History using Langchain_ ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "#Create the history Store\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "#Wrapper that appends to and replays from `history`\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d073bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "store ={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8331938",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n",
    "config = {'configurable' :{'session_id':'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2705325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Aswin! \\n\\nIt's nice to meet you. Being a data engineer at Infosys sounds like a really interesting job!  \\n\\nWhat kind of projects are you working on these days?  Are you using any cool new technologies?  I'm always eager to learn more about what's happening in the data world. ðŸ˜Š \\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content='Hi I am Aswin ,I am a data Engineer with Infosys')],\n",
    "    config = config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abcceda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You said your name is Aswin earlier in our conversation.  \\n\\nIs there something else you'd like to talk about?  ðŸ˜„ \\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43d8d6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I still don't know your name! You'll have to tell me. ðŸ˜Š \\n\\nWhat's your name?  \\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {'configurable' :{'session_id':'chat2'}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config2\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c23c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
