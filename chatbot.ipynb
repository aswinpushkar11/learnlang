{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ed84ce",
   "metadata": {},
   "source": [
    "## _LLM Powered Chatbot_ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f16436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bb93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6dc75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f545eaad750>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f545eaaebc0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Chatmodel\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='gemma2-9b-it',\n",
    "                 groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae07a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Aswin! \\n\\nIt's nice to meet you.  \\n\\nAs a data engineer at Infosys, what kind of projects are you working on?  Are you using any interesting technologies? I'm always interested in learning more about the work data engineers do.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "response = model.invoke([\n",
    "    HumanMessage(content='Hi I am Aswin ,I am a data Engineer with Infosys')\n",
    "])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d407e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Aswin and that you are a Data Engineer at Infosys. üòä  \\n\\nIs there anything else you'd like to chat about?  Perhaps you'd like to discuss data engineering trends or challenges you're facing?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 113, 'total_tokens': 168, 'completion_time': 0.1, 'prompt_time': 0.005387591, 'queue_time': 0.24632072000000002, 'total_time': 0.105387591}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-47263265-fc39-441c-9dad-00c574218b1a-0', usage_metadata={'input_tokens': 113, 'output_tokens': 55, 'total_tokens': 168})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content='Hi I am Aswin ,I am a data Engineer with Infosys'),\n",
    "    AIMessage(content =\"Hi Aswin,\\n\\nIt's nice to meet you! It's great to hear you're a Data Engineer at Infosys. That's a fascinating field. \\n\\nWhat kind of data engineering projects are you currently working on?  \\n\\nI'm always eager to learn more about how data is being used to solve real-world problems.\\n\"),\n",
    "    HumanMessage(content=\"Whats my name and occupation?\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444946a",
   "metadata": {},
   "source": [
    "#### _Message History using Langchain_ ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987a5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "#Create the history Store\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "#Wrapper that appends to and replays from `history`\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d073bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "store ={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8331938",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n",
    "config = {'configurable' :{'session_id':'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2705325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Aswin! üëã  \\n\\nIt's great to know you're a Data Engineer at Infosys. That's a really exciting field! \\n\\nWhat kind of projects are you working on these days?  Are there any particular technologies or challenges you're particularly interested in?  \\n\\nI'm always eager to learn more about what people are doing in the world of data engineering. üòÑ\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content='Hi I am Aswin ,I am a data Engineer with Infosys')],\n",
    "    config = config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcceda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Aswin.  üòä  I remember!  We just met.  \\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43d8d6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name.\\n\\nIf you'd like to tell me your name, I'd be happy to use it!\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {'configurable' :{'session_id':'chat2'}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config2\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8080e",
   "metadata": {},
   "source": [
    "### _ChatPromptTemplate_ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b78eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system','You are a helpful assistant,Answer all the questions asked'),\n",
    "      MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc079454",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a93bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(chain,\n",
    "                                                 get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dab16638",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'chat3'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d907bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content='My name is Aswin,I am a data engineer')],\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a02a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Aswin! It's nice to meet you.\\n\\nI'm ready to help with any questions you have. Since you're a data engineer, I imagine you have a lot of interesting things to ask about data, technology, or maybe even just need a break and want to chat.\\n\\nWhat can I do for you today?  \\n\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a08b5c",
   "metadata": {},
   "source": [
    "##### _Case2 - Parametersing the output prompt template_ #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "791fff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ChatPromptTemplate.from_messages(\n",
    "    [('system','You are a helpful assistant,answer in {language}'),\n",
    "    MessagesPlaceholder(variable_name='messages')  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11bdf88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompts|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4132055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= chain.invoke(\n",
    "    {\"messages\":[HumanMessage(content = 'I am Aswin Pushkar,I am a data engineer')],\n",
    "     \"language\":\"Hindi\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fa704b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Aswin Pushkar!\\n\\n‡§Æ‡•Å‡§ù‡•á ‡§ú‡§æ‡§®‡§ï‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡§æ ‡§ï‡§ø ‡§Ü‡§™ ‡§è‡§ï ‡§°‡•á‡§ü‡§æ ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§π‡•à‡§Ç‡•§ \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?  ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§ï‡•ã‡§à ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§ï‡•ã‡§à ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ú‡§ø‡§∏‡•á ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? \\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd007ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
